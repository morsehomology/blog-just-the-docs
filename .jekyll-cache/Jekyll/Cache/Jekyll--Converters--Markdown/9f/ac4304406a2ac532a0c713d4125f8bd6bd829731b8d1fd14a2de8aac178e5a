I"Ò<details>
  <summary>
  </summary>

- [1. Background on Transformers](#1-background-on-transformers)
  - [1.1. Transformers vs. RNN's (Motivation 1)](#11-transformers-vs-rnns-motivation-1)
  - [1.2. Useful info](#12-useful-info)
    - [1.2.1. Softmax](#121-softmax)
- [2. Workflow for AAYN model](#2-workflow-for-aayn-model)
- [3. Transformer architectures](#3-transformer-architectures)
- [4. Comments](#4-comments)

</details>

<h1 id="1-background-on-transformers">1. Background on Transformers</h1>

<h2 id="11-transformers-vs-rnns-motivation-1">1.1. Transformers vs. RNN‚Äôs (Motivation 1)</h2>

<p><strong>Idea:</strong> Framing transformers as an alternative to RNN‚Äôs for ‚Äúsequence-to-sequence‚Äù mapping, e.g., for translation</p>

<p>Here, each network will represent a function $f: X \to X‚Äô$, where $X$ and $X‚Äô$ denote the spaces of input and output sequences, respectively.</p>

<p>More specifically, let $T, T‚Äô$ denote the spaces of input and output tokens, and let $I$ denote the index set (need to elaborate on the structure of $I$). Then</p>

\[X = \{I \to T\}\]

<p>and</p>

\[X' = \{I \to T'\}\]

<p>Let $M = {X \to X‚Äô}$ denote the space of all sequence-to-sequence mappings.</p>

<h2 id="12-useful-info">1.2. Useful info</h2>

<h3 id="121-softmax">1.2.1. Softmax</h3>

<p>Softmax function $\rho: \R^n \to \R^n$,</p>

\[\rho\left(x_i\right)=\frac{\exp \left(x_i\right)}{\sum_j \exp \left(x_j\right)}\]

<p>Possible ways to think about it:</p>

<ul>
  <li>Define $\rho_t$ by</li>
</ul>

\[\rho_t\left(x_i\right)=\frac{\exp \left(t x_i\right)}{\sum_j \exp \left(t x_j\right)}\]

<p>for $t\in \R^+$.</p>

<h1 id="2-workflow-for-aayn-model">2. Workflow for AAYN model</h1>

<ol>
  <li>Inputs come in as a sequence of tokens
2.</li>
</ol>

<h1 id="3-transformer-architectures">3. Transformer architectures</h1>

<p>References:</p>

<p>What defines a transformer? What are its important properties, how does it differ from other kinds of architectures (and what are the current views of the effects of these differences?)</p>

<h1 id="4-comments">4. Comments</h1>

<p>| Comments: |
| ‚Äî‚Äî‚Äî |</p>

<table>
  <tbody>
    <tr>
      <td>Is there any interesting way to relate some of these transformer vs RNN ideas to the distinc</td>
    </tr>
  </tbody>
</table>
:ET