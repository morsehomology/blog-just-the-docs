I"¿	<details>
  <summary>
  </summary>

- [1.1. Background on Transformers](#11-background-on-transformers)
  - [1.1.1. Framing transformers as an alternative to RNN‚Äôs for ‚Äúsequence-to-sequence‚Äù mapping, e.g., for translation (Idea 1)](#111-framing-transformers-as-an-alternative-to-rnns-for-sequence-to-sequence-mapping-eg-for-translation-idea-1)
  - [1.1.2. Useful info](#112-useful-info)
    - [1.1.2.1. Softmax](#1121-softmax)
- [1.2. Workflow for AAYN model](#12-workflow-for-aayn-model)
- [1.3. Transformer architectures](#13-transformer-architectures)
- [1.4. Comments](#14-comments)

</details>

<h1 id="11-background-on-transformers">1.1. Background on Transformers</h1>

<h2 id="111-framing-transformers-as-an-alternative-to-rnns-for-sequence-to-sequence-mapping-eg-for-translation-idea-1">1.1.1. Framing transformers as an alternative to RNN‚Äôs for ‚Äúsequence-to-sequence‚Äù mapping, e.g., for translation (Idea 1)</h2>

<p>Here, each network will represent a function $f: X \to X‚Äô$, where $X$ and $X‚Äô$ denote the spaces of input and output sequences, respectively.</p>

<p>More specifically, let $T, T‚Äô$ denote the spaces of input and output tokens, and let $I$ denote the index set (need to elaborate on the structure of $I$). Then</p>

\[X = \{I \to T\}\]

<p>and</p>

\[X' = \{I \to T'\}\]

<p>Let $M = {X \to X‚Äô}$ denote the space of all sequence-to-sequence mappings.</p>

<h2 id="112-useful-info">1.1.2. Useful info</h2>

<h3 id="1121-softmax">1.1.2.1. Softmax</h3>

<p>Softmax function $\rho: \R^n \to \R^n$,</p>

\[\rho\left(x_i\right)=\frac{\exp \left(x_i\right)}{\sum_j \exp \left(x_j\right)}\]

<p>Possible ways to think about it:</p>

<ul>
  <li>Define $\rho_t$ by</li>
</ul>

\[\rho_t\left(x_i\right)=\frac{\exp \left(t x_i\right)}{\sum_j \exp \left(t x_j\right)}\]

<p>for $t\in \R^+$.</p>

<h1 id="12-workflow-for-aayn-model">1.2. Workflow for AAYN model</h1>

<ol>
  <li>Inputs come in as a sequence of tokens
2.</li>
</ol>

<h1 id="13-transformer-architectures">1.3. Transformer architectures</h1>

<p>References:</p>

<p>What defines a transformer? What are its important properties, how does it differ from other kinds of architectures (and what are the current views of the effects of these differences?)</p>

<h1 id="14-comments">1.4. Comments</h1>

<p>| Comments: |
| ‚Äî‚Äî‚Äî |</p>

<table>
  <tbody>
    <tr>
      <td>Is there any interesting way to relate some of these transformer vs RNN ideas to the distinc</td>
    </tr>
  </tbody>
</table>
:ET